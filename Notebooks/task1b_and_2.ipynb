{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import os\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.loadtxt(\"Solution_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = np.loadtxt(\"box.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Internal Caliberation marix\n",
    "focal_length = 2960.37845\n",
    "principal_points = (1841.68855, 1235.23369)\n",
    "camera_matrix = np.array([[focal_length,0,principal_points[0]],\n",
    "                         [0,focal_length,principal_points[1]],\n",
    "                         [0,0,1]],dtype=\"double\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ray-Box intersection method\n",
    "def intersection(Op_x,Op_y,Op_z,Dir_x,Dir_y,Dir_z):\n",
    "    P_min_x = 0.0\n",
    "    P_min_y = 0.0\n",
    "    P_min_z = 0.0\n",
    "    P_max_x = 0.165\n",
    "    P_max_y = 0.063\n",
    "    P_max_z = 0.093\n",
    "    \n",
    "    ray_min = (P_min_x - Op_x)/Dir_x\n",
    "    ray_max = (P_max_x - Op_x)/Dir_x\n",
    "    \n",
    "    \n",
    "    if(ray_min > ray_max):\n",
    "        ray_min,ray_max = ray_max,ray_min\n",
    "    \n",
    "    ray_min_y = (P_min_y - Op_y)/Dir_y\n",
    "    ray_max_y = (P_max_y - Op_y)/Dir_y\n",
    "    \n",
    "    if(ray_min_y > ray_max_y):\n",
    "        ray_min_y,ray_max_y = ray_max_y,ray_min_y\n",
    "        \n",
    "    if((ray_min > ray_max_y) or (ray_min_y) > ray_max):\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    if(ray_min_y > ray_min):\n",
    "        ray_min = ray_min_y\n",
    "        \n",
    "    if(ray_max_y < ray_max):\n",
    "        ray_max = ray_max_y\n",
    "        \n",
    "    ray_min_z = (P_min_z - Op_z)/Dir_z\n",
    "    ray_max_z = (P_max_z - Op_z)/Dir_z\n",
    "    \n",
    "    if(ray_min_z > ray_max_z):\n",
    "        ray_min_z,ray_max_z = ray_max_z,ray_min_z\n",
    "        \n",
    "    if((ray_min > ray_max_z) or (ray_min_z > ray_max)):\n",
    "        return 0\n",
    "    \n",
    "    if(ray_min_z > ray_min):\n",
    "        ray_min = ray_min_z\n",
    "        \n",
    "    if(ray_max_z < ray_max):\n",
    "        ray_max = ray_max_z\n",
    "    \n",
    "    if(ray_min < ray_max):\n",
    "        return ray_min\n",
    "    else:\n",
    "        return ray_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"/home/aditya/Documents/Sem_3/TDCV/Project_1/data_task1/init_texture/\"\n",
    "images = [\"DSC_9743.JPG\",\"DSC_9744.JPG\",\"DSC_9745.JPG\",\"DSC_9746.JPG\",\"DSC_9747.JPG\",\"DSC_9748.JPG\",\"DSC_9749.JPG\",\"DSC_9750.JPG\"]\n",
    "i = 0\n",
    "filtered_coordinates = []\n",
    "desc_filtered = []\n",
    "for i in range(len(images)):\n",
    "    \n",
    "    rotation_vector = s[i][0:3].reshape(3,1)\n",
    "    translation_vector = s[i][3:6].reshape(3,1)\n",
    "    \n",
    "    rotation_matrix = np.zeros(shape=(3,3))\n",
    "    cv2.Rodrigues(rotation_vector,rotation_matrix) #Compute rotation matrix\n",
    "    Q = np.dot(camera_matrix,rotation_matrix)\n",
    "    q = np.dot(camera_matrix,translation_vector)\n",
    "    opt_centre = -np.dot(np.linalg.inv(Q),q) #Compute optical centre\n",
    "    \n",
    "    \n",
    "    img = cv2.imread(os.path.join(rootdir + images[i])) #Read the images\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(gray, None)\n",
    "    kp_img = cv2.drawKeypoints(gray,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    cv2.imwrite('sift_keypoints_' + str(9743 + i) + '.jpg',kp_img)\n",
    "    \n",
    "    count = 0\n",
    "    Y = []\n",
    "    descriptor = []\n",
    "    dir = np.zeros(shape = (np.shape(des)[0],3))\n",
    "    sum = np.zeros(shape=(3,1))\n",
    "    for j in range(np.shape(des)[0]):\n",
    "        dir[j] = np.dot(np.linalg.inv(Q),[kp[j].pt[0],kp[j].pt[1],1])\n",
    "        val = intersection(opt_centre[0],opt_centre[1],opt_centre[2],dir[j][0],dir[j][1],dir[j][2])\n",
    "        if(val != 0):\n",
    "            prod = val * dir[j]\n",
    "            prod = prod.reshape(3,1)\n",
    "            sum = opt_centre + prod\n",
    "            count += 1\n",
    "            sum=np.ravel(sum)\n",
    "            Y.append(sum)\n",
    "            descriptor.append(des[j])\n",
    "    \n",
    "    for m in range(count):\n",
    "        filtered_coordinates.append(Y[m]) #Append the 3D coordinates\n",
    "        desc_filtered.append(descriptor[m]) #Append the respective descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_filtered = np.array(desc_filtered)\n",
    "img_1 = cv2.imread(\"/home/aditya/Documents/Sem_3/TDCV/Project_1/tracking/color_000006.JPG\",cv2.IMREAD_COLOR)\n",
    "sift_1 = cv2.SIFT_create()\n",
    "kp_1,des_1 = sift_1.detectAndCompute(img_1,None)\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.match(des_1,desc_filtered)\n",
    "\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "matches = matches[:66] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation vector:\n",
      "[[ 2.20681372]\n",
      " [-0.69803872]\n",
      " [ 0.26384952]]\n",
      "Translation vector:\n",
      "[[-0.08342262]\n",
      " [-0.03428778]\n",
      " [ 0.81656125]]\n"
     ]
    }
   ],
   "source": [
    "image_points = []\n",
    "threed_points = []\n",
    "for i in range(len(matches)):\n",
    "    image_points.append(kp_1[matches[i].queryIdx].pt)\n",
    "    threed_points.append(filtered_coordinates[matches[i].trainIdx])\n",
    "image_points = np.array(image_points) \n",
    "threed_points = np.array(threed_points)\n",
    "dist_coeff = None\n",
    "\n",
    "#Apply PnPRansac\n",
    "success,rotation_vec_1,translation_vec_1,inliers = cv2.solvePnPRansac(threed_points,image_points,camera_matrix,dist_coeff,iterationsCount=400,reprojectionError=1)\n",
    "\n",
    "print(\"Rotation vector:\\n{0}\".format(rotation_vec_1))\n",
    "print(\"Translation vector:\\n{0}\".format(translation_vec_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file = open(\"solution_task_2.txt\",'w')\n",
    "\n",
    "np.savetxt(file,rotation_vec_1.flatten(),newline=\"\\t\")\n",
    "np.savetxt(file,translation_vec_1.flatten(),newline=\"\\t\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(camera_mat,rot_mat,t_vec,img_point):\n",
    "    return ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain the SIFT keypoints of the subsequqent images\n",
    "img_2 = cv2.imread(\"/home/aditya/Documents/Sem_3/TDCV/Project_1/tracking/color_000007.JPG\",cv2.IMREAD_COLOR)\n",
    "sift_2 = cv2.SIFT_create()\n",
    "kp_2,ds_2 = sift_new.detectAndCompute(img_2,None)\n",
    "\n",
    "bf = cv2.BFMatcher()\n",
    "matches_2 = bf.match(ds_2,desc_filtered)\n",
    "\n",
    "matches_2 = sorted(matches_2, key = lambda x:x.distance)\n",
    "matches_2 = matches_2[:100]\n",
    "\n",
    "three_dim_points = []\n",
    "image_plane_points = []\n",
    "for i in range(len(matches_2)):\n",
    "    three_dim_points.append(filtered_coordinates[matches_2[i].trainIdx])\n",
    "    image_plane_points.append(kp_2[matches_2[i].queryIdx].pt)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
